{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "import os \n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"langchain-tutorial\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\", \n",
    "    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\", \n",
    "    \"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\"\n",
    "]   \n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalization\": True}\n",
    "\n",
    "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, \n",
    "    model_kwargs=model_kwargs, \n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 250, \n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "docs_split = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vector store\n",
    "vectore_store = Chroma.from_documents(\n",
    "    docs_split, \n",
    "    collection_name=\"rag-chroma\", \n",
    "    embedding=hf_embeddings\n",
    ")\n",
    "\n",
    "retriever = vectore_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n"
     ]
    }
   ],
   "source": [
    "# Router\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Data Modelc\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a query to relevant datasource\"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectore_store\", \"web_search\"] = Field(\n",
    "        ..., \n",
    "        description=\"Given a user question choose to route it  to either web search or a vector store.\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "structure_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt\n",
    "system_prompt = \"\"\"You are an expert at routing a user question to a vector store or a websearch. The vectorstore contains documents related to agents. Prompt engineering and adversarial attacks. Use the vectorstore for questions on these topics, otherwise use web-search.\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt), \n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt | structure_llm_router\n",
    "\n",
    "print(question_router.invoke({\n",
    "    \"question\": \"What are different types of LLM hallucinations\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_25180\\3643235547.py:26: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "# Retrieval Grader\n",
    "\n",
    "# DataModel\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance chack on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents retrieved are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "llm = ChatGroq(temperature=0)\n",
    "structure_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "system_prompt = \"\"\"You are a hrader assessing relevance of a retrived documents to a user question\\n. If the documents contains keyword(s) or semantic meaning related to the user question. grade it as relevant. If it does not need to be a stringent test. The goal is to filter out erroneous retrievals. Give a binary score 'yes' or 'no'. score to indicate whether the document is relevant to the question or not.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"Retrieved documents: \\n\\n {document} \\n\\n relevant question: {question}\") \n",
    "    ]\n",
    ")\n",
    "\n",
    "reteival_grader = grade_prompt | structure_llm_grader\n",
    "question = \"llm-halluncatios\"\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "doc_text = docs[1].page_content\n",
    "\n",
    "print(reteival_grader.invoke(\n",
    "    {\n",
    "        \"question\": question, \n",
    "        \"document\": doc_text\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hallucination in large language models (LLMs) refers to the model generating unfaithful, fabricated, inconsistent, or nonsensical content. The focus here is on extrinsic hallucination, where the model output is fabricated and not grounded by the provided context or world knowledge. To avoid hallucination, LLMs should be factual and acknowledge when they don't know the answer.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate \n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt \n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "generation = rag_chain.invoke(\n",
    "    {\n",
    "        \"context\": docs, \n",
    "        \"question\": question\n",
    "    }\n",
    ")\n",
    "\n",
    "generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
