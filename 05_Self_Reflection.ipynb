{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "import os \n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"langchain-tutorial\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in d:\\learning rag\\.venv\\lib\\site-packages (0.5.20)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (0.115.5)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\learning rag\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (3.7.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (4.67.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (1.68.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (0.13.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (3.10.11)\n",
      "Requirement already satisfied: httpx>=0.27.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\learning rag\\.venv\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in d:\\learning rag\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\learning rag\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\learning rag\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in d:\\learning rag\\.venv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
      "Requirement already satisfied: anyio in d:\\learning rag\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in d:\\learning rag\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\learning rag\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
      "Requirement already satisfied: idna in d:\\learning rag\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in d:\\learning rag\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\learning rag\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\learning rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\learning rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\learning rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.36.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\learning rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in d:\\learning rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\learning rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in d:\\learning rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in d:\\learning rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in d:\\learning rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in d:\\learning rag\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\learning rag\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in d:\\learning rag\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.28.3)\n",
      "Requirement already satisfied: sympy in d:\\learning rag\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.49b2 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in d:\\learning rag\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in d:\\learning rag\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\learning rag\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\learning rag\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\learning rag\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\learning rag\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\learning rag\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\learning rag\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\learning rag\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\learning rag\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in d:\\learning rag\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\learning rag\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\learning rag\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\learning rag\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\learning rag\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\learning rag\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\learning rag\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in d:\\learning rag\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\learning rag\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\learning rag\\.venv\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\learning rag\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\learning rag\\.venv\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\learning rag\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\learning rag\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in d:\\learning rag\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\learning rag\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "d:\\Learning RAG\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\", \n",
    "    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\", \n",
    "    \"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\"\n",
    "]\n",
    "\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 250, \n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, \n",
    "    model_kwargs=model_kwargs, \n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=doc_splits, \n",
    "    collection_name = \"rag-chroma\", \n",
    "    embedding = hf_embeddings\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "# Retriveal Grader\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Data Model\n",
    "class GradeDocument(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved docuements\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLm with function call\n",
    "llm = ChatGroq(temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocument)\n",
    "\n",
    "# Prompt\n",
    "system_prompt = \"\"\"You are a grader assessing relevance of a retrieved docuements to a user's question.\\n\n",
    "It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "If the docuement contains keyword(s) or semantic meaning related to the user's question, grade it as relevant\\n\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question or not.\n",
    "\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"Retrieved document:\\n\\n {document}\\n\\n User Question: {question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "question = \"LLM hallucination\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "doc_text = docs[1].page_content\n",
    "\n",
    "print(retrieval_grader.invoke({\n",
    "    \"question\": question, \n",
    "    \"document\": doc_text\n",
    "}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallucination in large language models (LLMs) refers to the model generating unfaithful, fabricated, inconsistent, or nonsensical content. This response focuses on extrinsic hallucination, which occurs when the model output is fabricated and not grounded by either the provided context or world knowledge. It is differentiated from in-context hallucination, where the model output should be consistent with the source content. Extrinsic hallucinations can be caused by pre-training data issues, such as out-of-date, missing, or incorrect information, and by introducing new knowledge during the fine-tuning stage.\n"
     ]
    }
   ],
   "source": [
    "# Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# CHAIN\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "generation = rag_chain.invoke({\n",
    "    \"context\": docs, \n",
    "    \"question\": question\n",
    "})\n",
    "\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='no')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hallucination Grader\n",
    "\n",
    "# Data Model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"Binary score for grading hallucination\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "system_prompt = \"\"\"You are a grader assessing whether an LLM is grounded in / supported by a set of retrieved facts. \\n Give a binary score \"yes' or 'no'. 'yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt), \n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation {generation}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "\n",
    "hallucination_grader.invoke({\n",
    "    \"documents\": docs, \n",
    "    \"generation\": generation\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Grader\n",
    "\n",
    "class AnswerGrader(BaseModel):\n",
    "    \"\"\"Binary score to assess answers\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "system_prompt = \"\"\"You are a grader assessing whether an answer addresses/resolves a question\\n Give a binary score 'yes' or 'no'. 'yes' means the answer resolves the problem\"\"\"\n",
    "\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "answer_grader_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt), \n",
    "        (\"human\", \"\"\"User question: \\n\\n {question} \\n\\n LLM Generation: {generation}\"\"\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader_chain = answer_grader_prompt | llm | structured_llm_grader\n",
    "\n",
    "answer_grader_chain.invoke({\n",
    "    \"question\": question, \n",
    "    \"generation\": generation\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
