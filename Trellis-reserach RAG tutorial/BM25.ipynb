{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25\n",
    "- Score highly chunks with words in common with the query\n",
    "- Weigh more heavily words that are infrequenct accross all chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true' # Allows tracing\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"langchain-tutorial\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in d:\\learning rag\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\learning rag\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\learning rag\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in d:\\learning rag\\.venv\\lib\\site-packages (from nltk) (4.67.0)\n",
      "Requirement already satisfied: colorama in d:\\learning rag\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.7 MB/s eta 0:00:00\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in d:\\learning rag\\.venv\\lib\\site-packages (from rank_bm25) (1.26.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize \n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "def find_closest_chunks_bm25(query, chunks, top_n=12):\n",
    "    \"\"\"\n",
    "    top_n = How many of the top chunks you wanna keep\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_chunks = [word_tokenize(chunk) for chunk in chunks]\n",
    "    bm25 = BM25Okapi(tokenized_chunks)\n",
    "\n",
    "    # Tokenizing the query\n",
    "    tokenized_query = word_tokenize(query)\n",
    "\n",
    "    # Get BM25 scored for the tokenized query\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    # Get the top N chunks\n",
    "    top_n_indices = np.argsort(scores)[::-1][:top_n]\n",
    "\n",
    "    return top_n_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Sure! Here's a large corpus of text about AI, with each paragraph separated by a newline:\",\n",
       " 'Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, and self-correction. AI has evolved significantly over the past few decades, from basic rule-based systems to advanced machine learning algorithms capable of performing complex tasks.',\n",
       " 'Machine learning, a subset of AI, focuses on building systems that can learn and improve from experience without being explicitly programmed. Algorithms like supervised learning, unsupervised learning, and reinforcement learning are commonly used to train models to perform tasks like classification, regression, and prediction.',\n",
       " 'Deep learning, a further subset of machine learning, utilizes neural networks with many layers to analyze and interpret complex data such as images, audio, and text. Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are popular architectures used in deep learning applications like image recognition and natural language processing.',\n",
       " 'Natural Language Processing (NLP) is a field within AI that enables machines to understand, interpret, and generate human language. Tasks in NLP include sentiment analysis, machine translation, and chatbots. Transformer-based models like GPT and BERT have revolutionized NLP by achieving state-of-the-art results in various benchmarks.',\n",
       " 'Computer vision is another key area of AI that allows machines to process and analyze visual data. Applications include facial recognition, object detection, and autonomous vehicles. Algorithms like YOLO and RetinaNet are widely used in real-time object detection tasks.',\n",
       " 'Reinforcement learning is an area of AI where agents learn to make decisions by interacting with their environment and receiving rewards or penalties. This technique is behind many breakthroughs, such as AlphaGo, which defeated human champions in the game of Go, and applications in robotics and simulation.',\n",
       " 'Ethics in AI is a growing concern as these technologies become more pervasive. Issues such as bias, data privacy, and the potential misuse of AI require careful consideration. Responsible AI development aims to ensure fairness, accountability, and transparency in AI systems.',\n",
       " 'Generative AI focuses on creating new content, such as images, music, or text. Models like GANs (Generative Adversarial Networks) and diffusion models are used for tasks like image synthesis and video generation. Generative Pre-trained Transformers (GPT) are widely used for text generation.',\n",
       " 'AI in healthcare has shown immense potential, from diagnosing diseases to personalizing treatment plans. AI models can analyze medical images, predict patient outcomes, and even assist in drug discovery, revolutionizing the way healthcare is delivered.',\n",
       " 'Edge AI refers to deploying AI models directly on devices rather than relying on centralized cloud servers. This approach enables real-time data processing with lower latency and enhanced privacy. Applications include smart home devices, autonomous vehicles, and wearable health monitors.',\n",
       " 'Explainable AI (XAI) is an initiative to make AI decisions more interpretable to humans. As AI systems are often perceived as \"black boxes,\" XAI aims to provide insights into how models reach conclusions, enhancing trust and accountability.',\n",
       " 'Feel free to copy and expand on these paragraphs for your RAG implementation! Let me know if you need more content.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/text_corpus.txt\", \"r\") as f:\n",
    "    paragraphs = f.readlines()\n",
    "\n",
    "# Define the list of unacceptable entries (strings to exclude)\n",
    "unacceptable_entries = [\"---\\n\", \"\\n\", \"---\"]\n",
    "\n",
    "# Filter out paragraphs that are exactly in unacceptable_entries\n",
    "paragraphs = [p for p in paragraphs if p not in unacceptable_entries]\n",
    "\n",
    "# Strip whitespace from each paragraph\n",
    "chunks = [p.strip() for p in paragraphs if p.strip()]\n",
    "\n",
    "# Display the filtered paragraphs\n",
    "chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is Explainable AI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m----> 3\u001b[0m indices \u001b[38;5;241m=\u001b[39m find_closest_chunks_bm25(query, chunks, \u001b[43mtop_n\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_n' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"What is Explainable AI\"\n",
    "n = 3\n",
    "indices = find_closest_chunks_bm25(query, chunks, top_n==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainable AI (XAI) is an initiative to make AI decisions more interpretable to humans. As AI systems are often perceived as \"black boxes,\" XAI aims to provide insights into how models reach conclusions, enhancing trust and accountability.\n",
      "Ethics in AI is a growing concern as these technologies become more pervasive. Issues such as bias, data privacy, and the potential misuse of AI require careful consideration. Responsible AI development aims to ensure fairness, accountability, and transparency in AI systems.\n",
      "AI in healthcare has shown immense potential, from diagnosing diseases to personalizing treatment plans. AI models can analyze medical images, predict patient outcomes, and even assist in drug discovery, revolutionizing the way healthcare is delivered.\n",
      "Reinforcement learning is an area of AI where agents learn to make decisions by interacting with their environment and receiving rewards or penalties. This technique is behind many breakthroughs, such as AlphaGo, which defeated human champions in the game of Go, and applications in robotics and simulation.\n",
      "Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, and self-correction. AI has evolved significantly over the past few decades, from basic rule-based systems to advanced machine learning algorithms capable of performing complex tasks.\n",
      "Computer vision is another key area of AI that allows machines to process and analyze visual data. Applications include facial recognition, object detection, and autonomous vehicles. Algorithms like YOLO and RetinaNet are widely used in real-time object detection tasks.\n",
      "Natural Language Processing (NLP) is a field within AI that enables machines to understand, interpret, and generate human language. Tasks in NLP include sentiment analysis, machine translation, and chatbots. Transformer-based models like GPT and BERT have revolutionized NLP by achieving state-of-the-art results in various benchmarks.\n",
      "Edge AI refers to deploying AI models directly on devices rather than relying on centralized cloud servers. This approach enables real-time data processing with lower latency and enhanced privacy. Applications include smart home devices, autonomous vehicles, and wearable health monitors.\n",
      "Sure! Here's a large corpus of text about AI, with each paragraph separated by a newline:\n",
      "Generative AI focuses on creating new content, such as images, music, or text. Models like GANs (Generative Adversarial Networks) and diffusion models are used for tasks like image synthesis and video generation. Generative Pre-trained Transformers (GPT) are widely used for text generation.\n",
      "Machine learning, a subset of AI, focuses on building systems that can learn and improve from experience without being explicitly programmed. Algorithms like supervised learning, unsupervised learning, and reinforcement learning are commonly used to train models to perform tasks like classification, regression, and prediction.\n",
      "Feel free to copy and expand on these paragraphs for your RAG implementation! Let me know if you need more content.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(chunks[index]) for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
